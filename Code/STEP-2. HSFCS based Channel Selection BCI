{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"STEP: 2--channel selection BCI","provenance":[{"file_id":"10F39e4jCcK7rgtf-QCa4RADbzAhERecT","timestamp":1637693415853},{"file_id":"1WnPcs4NNJw4G-Y5noJs_bYmCH-8NUS99","timestamp":1637691539598},{"file_id":"1_aNd9W_ox0bPqI3ULdUB0VDEOOAvN__A","timestamp":1637169672125}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"q5UDY40xrsZF"},"source":["from google.colab import drive\n","import pickle\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import chi2\n","from sklearn.feature_selection import SelectKBest, SelectPercentile\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold \n","from sklearn.neural_network import MLPClassifier\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","!pip install skfeature-chappers\n","drive.mount('/content/drive', force_remount = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTfibgB5c63Y","executionInfo":{"status":"ok","timestamp":1644322630300,"user_tz":-330,"elapsed":2,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}}},"source":["def emotion_label(labels, class_label):\n","\tem_labels = []\n","\tif(class_label == \"valence\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][0]>5): # high valence\n","\t\t\t\tem_labels.append(1)\n","\t\t\telse: # low valence\n","\t\t\t\tem_labels.append(0)\n","\t\treturn em_labels\n","\telif(class_label == \"arousal\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][1]>5): # high arousal\n","\t\t\t\tem_labels.append(1)\n","\t\t\telse: # low arousal\n","\t\t\t\tem_labels.append(0)\n","\t\treturn em_labels\n","\telif(class_label == \"all\"):\n","\t\tfor i in range(0, labels.shape[0]):\n","\t\t\tif (labels[i][0]>5): # high valence\n","\t\t\t\tif(labels[i][1]>5): # high arousal\n","\t\t\t\t\tem_labels.append(1) # HVHA\n","\t\t\t\telse:\n","\t\t\t\t\tem_labels.append(0) # HVLA\n","\t\t\telse: # low valence\n","\t\t\t\tif(labels[i][1]>5): # high arousal\n","\t\t\t\t\tem_labels.append(2) # LVHA\n","\t\t\t\telse: # low arousal\n","\t\t\t\t\tem_labels.append(3) # LVLA\n","\t\treturn em_labels"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_3jkQEH0jZW6"},"source":["# Fisher Score"]},{"cell_type":"code","metadata":{"id":"kxJTyBtEeqHy"},"source":["import numpy as np\n","from skfeature.utility.construct_W import construct_W\n","from scipy.sparse import diags\n","def fisher_score(X, y):\n","    \"\"\"\n","    This function implements the fisher score feature selection, steps are as follows:\n","    1. Construct the affinity matrix W in fisher score way\n","    2. For the r-th feature, we define fr = X(:,r), D = diag(W*ones), ones = [1,...,1]', L = D - W\n","    3. Let fr_hat = fr - (fr'*D*ones)*ones/(ones'*D*ones)\n","    4. Fisher score for the r-th feature is score = (fr_hat'*D*fr_hat)/(fr_hat'*L*fr_hat)-1\n","    Input\n","    -----\n","    X: {numpy array}, shape (n_samples, n_features)\n","        input data\n","    y: {numpy array}, shape (n_samples,)\n","        input class labels\n","    Output\n","    ------\n","    score: {numpy array}, shape (n_features,)\n","        fisher score for each feature\n","    Reference\n","    ---------\n","    He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n","    Duda, Richard et al. \"Pattern classification.\" John Wiley & Sons, 2012.\n","    \"\"\"\n","    # Construct weight matrix W in a fisherScore way\n","    kwargs = {\"neighbor_mode\": \"supervised\", \"fisher_score\": True, 'y': y}\n","    W = construct_W(X, **kwargs)\n","\n","    # build the diagonal D matrix from affinity matrix W\n","    D = np.array(W.sum(axis=1))\n","    L = W\n","    tmp = np.dot(np.transpose(D), X)\n","    D = diags(np.transpose(D), [0])\n","    Xt = np.transpose(X)\n","    t1 = np.transpose(np.dot(Xt, D.todense()))\n","    t2 = np.transpose(np.dot(Xt, L.todense()))\n","    # compute the numerator of Lr\n","    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n","    # compute the denominator of Lr\n","    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n","    # avoid the denominator of Lr to be 0\n","    D_prime[D_prime < 1e-12] = 10000\n","    lap_score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n","\n","    # compute fisher score from laplacian score, where fisher_score = 1/lap_score - 1\n","    score = 1.0/lap_score - 1\n","    return np.transpose(score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def feature_wise_mean(X, i):\n","  # ith feature\n","  mysum  = 0\n","  for k in range(0, X.shape[0]):\n","    mysum = mysum + X[k][i]\n","  return mysum/X.shape[0]\n","def compute_sigma_and_uij(X, y, i, j):\n","  draft = []\n","  for s in range(0, X.shape[0]):\n","    if(y[s]==j):\n","      draft.append(X[s][i])\n","  draft = np.array(draft)\n","  return np.mean(draft), np.var(draft)\n","def fisher_score_without_laplace(X, y):\n","  f_score = np.ones(X.shape[1])\n","  # how many class\n","  classes = list(set(y))\n","  nj = np.ones(len(classes))\n","  # compute no of samples in each class\n","  for s in range(0, len(classes)):\n","    count_class = 0\n","    for k in range(0, X.shape[0]):\n","      if(y[k]==classes[s]):\n","        count_class = count_class + 1\n","    nj[s] = count_class\n","  for i in range(0, X.shape[1]):\n","    # for each feature compute the f score \n","    ui = feature_wise_mean(X, i)\n","    upper, lower = 0, 0\n","    for j in classes:\n","      uij, sigma_ij = compute_sigma_and_uij(X, y, i, j)\n","      upper = upper + nj[j]*((uij-ui)**2)\n","      lower = lower + nj[j]*(sigma_ij**2)\n","    f_score[i] = upper/lower\n","  return f_score"],"metadata":{"id":"O8mpTHurF9ZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yVtuzexSoN1L"},"source":["def get_fisher_score(subject_name, em_labels):\n","  mypath = \"/content/drive/MyDrive/Sequential methods for channel selection/our code/\" + subject_name + \"/\" + subject_name\n","  # for theta band\n","  data_theta = pd.read_csv(mypath + '_theta.csv')\n","  X, y = np.array(data_theta), np.array(em_labels)\n","  f_score_theta = fisher_score(X, y)\n","  #print(f_score_theta)\n","  # for alpha band\n","  data_alpha = pd.read_csv(mypath + '_alpha.csv')\n","  X, y = np.array(data_alpha), np.array(em_labels)\n","  f_score_alpha = fisher_score(X, y)\n","  #print(f_score_alpha)\n","  # for beta band\n","  data_beta = pd.read_csv(mypath + '_beta.csv')\n","  X, y = np.array(data_beta), np.array(em_labels)\n","  f_score_beta = fisher_score(X, y)\n","  # for gamma band\n","  data_gamma = pd.read_csv(mypath + '_gamma.csv')\n","  X, y = np.array(data_gamma), np.array(em_labels)\n","  f_score_gamma = fisher_score(X, y)\n","  # Total Avearge F-Score (Theta, Alpha, Beta, Gamma)\n","  final_f_score = (f_score_theta + f_score_alpha + f_score_beta + f_score_gamma)/4\n","  eeg_channels = np.array([\"Fp1\", \"AF3\", \"F3\", \"F7\", \"FC5\", \"FC1\", \"C3\", \"T7\", \"CP5\", \"CP1\", \"P3\", \"P7\", \"PO3\", \"O1\", \"Oz\", \"Pz\", \"Fp2\", \"AF4\", \"Fz\", \"F4\", \"F8\", \"FC6\", \"FC2\", \"Cz\", \"C4\", \"T8\", \"CP6\", \"CP2\", \"P4\", \"P8\", \"PO4\", \"O2\"])\n","  fvalues = pd.Series(final_f_score)\n","  fvalues.index = eeg_channels\n","  fvalues.sort_values(ascending=False)\n","  fvalues.to_csv('fscore_final.csv')\n","  #fvalues.sort_values(ascending = False).plot.bar(figsize=(10,8))\n","  shyam = fvalues.sort_values(ascending = False)\n","  da = pd.DataFrame(shyam)\n","  da.to_csv(\"channel_rank.csv\")\n","  cr = pd.read_csv(\"channel_rank.csv\")\n","  sort_channel_name = list(cr[\"Unnamed: 0\"])\n","  return sort_channel_name"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GJHHjtp-rOo_"},"source":["# Classification"]},{"cell_type":"code","metadata":{"id":"rxoQsqyl-sC-"},"source":["#Loading the dataset\n","def svmclassifier(channel_name, status = False):\n","  channel_names = []\n","  mypath = \"/content/drive/MyDrive/Sequential methods for channel selection/our code/\" + subject_name + \"/\" + subject_name\n","  data = pd.read_csv(mypath + '.csv')\n","  for i in range(0, len(channel_name)):\n","    draft = channel_name[i]\n","    channel_names.append(draft + \"_alpha\")\n","    channel_names.append(draft + \"_beta\")\n","    channel_names.append(draft + \"_gamma\")\n","    channel_names.append(draft + \"_theta\")\n","  x = data[channel_names]\n","  y = np.array(em_labels)\n","  # Implementing cross validation\n","  k = 40\n","  kf = KFold(n_splits = k, shuffle = status)\n","  acc_score = []\n","  for train_index , test_index in kf.split(x):\n","      x_train , x_test = x.iloc[train_index,:],x.iloc[test_index,:]\n","      y_train , y_test = y[train_index] , y[test_index]\n","      model = svm.SVC(kernel='poly')\n","      model.fit(x_train, y_train)\n","      pred_values = model.predict(x_test)\n","      #pred_values = model.predict(x_test)\n","      acc = accuracy_score(pred_values , y_test)\n","      acc_score.append(acc)\n","  avg_acc_score = sum(acc_score)/k\n","  return avg_acc_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PhZZyG55qSM"},"source":["def growing_phase(channel_name):\n","  mypath = \"/content/drive/MyDrive/Sequential methods for channel selection/our code/\" + subject_name + \"/\" + subject_name\n","  data = pd.read_csv(mypath + '.csv')\n","  cn = channel_name[0]\n","  acc = svmclassifier([cn])\n","  cn_list = []\n","  cn_list.append(cn)\n","  sort_cn = []\n","  for i in range(1, len(channel_name)):\n","    cur_cn = channel_name[i]\n","    cn_list.append(cur_cn)\n","    cur_acc = svmclassifier(cn_list)\n","    if(cur_acc<acc):\n","      # remove the curent channel name\n","      #print(\"Removing channel name: \", cur_cn)\n","      cn_list.remove(cur_cn)\n","    else:\n","      acc = cur_acc\n","  print(\"Accuracy in Growing Phase: \", acc)\n","  print(\"No of selected channels in Growing Phase: \", len(cn_list))\n","  print(\"Channels selected in Growing Phase: \", cn_list)\n","  return cn_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7MX6mnyGklNo"},"source":["def pruning_phase_get_fscore(optimal_channel_name, subject_name, em_labels):\n","  ocn = []\n","  mypath = \"/content/drive/MyDrive/Sequential methods for channel selection/our code/\" + subject_name + \"/\" + subject_name\n","  # for theta band\n","  data_theta = pd.read_csv(mypath + '_theta.csv')\n","  # select those particular channels theta band value only\n","  for i in range(0, len(optimal_channel_name)):\n","    ocn.append(optimal_channel_name[i] + \"_theta\")\n","  draft_theta = data_theta[ocn]\n","  X, y = np.array(draft_theta), np.array(em_labels)\n","  f_score_theta = fisher_score(X, y)\n","  # for alpha band\n","  data_alpha = pd.read_csv(mypath + '_alpha.csv')\n","  ocn = []\n","  # select those particular channels alpha band value only\n","  for i in range(0, len(optimal_channel_name)):\n","    ocn.append(optimal_channel_name[i] + \"_alpha\")\n","  draft_alpha = data_alpha[ocn]\n","  X, y = np.array(draft_alpha), np.array(em_labels)\n","  f_score_alpha = fisher_score(X, y)\n","  # for beta band\n","  data_beta = pd.read_csv(mypath + '_beta.csv')\n","  ocn = []\n","  # select those particular channels beta band value only\n","  for i in range(0, len(optimal_channel_name)):\n","    ocn.append(optimal_channel_name[i] + \"_beta\")\n","  draft_beta = data_beta[ocn]\n","  X, y = np.array(draft_beta), np.array(em_labels)\n","  f_score_beta = fisher_score(X, y)\n","  # for gamma band\n","  data_gamma = pd.read_csv(mypath + '_gamma.csv')\n","  ocn = []\n","  # select those particular channels alpha band value only\n","  for i in range(0, len(optimal_channel_name)):\n","    ocn.append(optimal_channel_name[i] + \"_gamma\")\n","  draft_gamma = data_gamma[ocn]\n","  X, y = np.array(draft_gamma), np.array(em_labels)\n","  f_score_gamma = fisher_score(X, y)\n","  # Total Avearge F-Score (Theta, Alpha, Beta, Gamma)\n","  final_f_score = (f_score_theta + f_score_alpha + f_score_beta + f_score_gamma)/4\n","  fvalues = pd.Series(final_f_score)\n","  fvalues.index = optimal_channel_name\n","  fvalues.sort_values(ascending=False)\n","  fvalues.to_csv('fscore_final.csv')\n","  #fvalues.sort_values(ascending = False).plot.bar(figsize=(10,8))\n","  shyam = fvalues.sort_values(ascending = False)\n","  da = pd.DataFrame(shyam)\n","  da.to_csv(\"channel_rank.csv\")\n","  cr = pd.read_csv(\"channel_rank.csv\")\n","  sort_channel_name = list(cr[\"Unnamed: 0\"])\n","  return sort_channel_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Vg5tC-1sq8p"},"source":["def pruning_phase(sort_channel_name):\n","  # check the accuracy for taking all the channels\n","  acc = svmclassifier(sort_channel_name)\n","  if(len(sort_channel_name)==1):\n","    print(\"Accuracy in Pruning Phase: \", acc)\n","    print(\"No of selected channels in Pruning Phase: \", len(sort_channel_name))\n","    print(\"Channels selected in Pruning Phase: \", sort_channel_name)\n","    return sort_channel_name\n","  for i in range(0, len(sort_channel_name)):\n","    cur_cn = sort_channel_name[0:(len(sort_channel_name)-i-1)] # remove for the last channel\n","    cur_acc = svmclassifier(cur_cn)\n","    if(cur_acc>acc): # accuracy improved then remove that channel\n","      acc = cur_acc\n","      continue\n","    else: # take that channel\n","      cur_cn = sort_channel_name[0:(len(sort_channel_name)-i)]\n","      break\n","  print(\"Accuracy in Pruning Phase: \", acc)\n","  print(\"No of selected channels in Pruning Phase: \", len(cur_cn))\n","  print(\"Channels selected in Pruning Phase: \", cur_cn)\n","  return cur_cn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hg-GPJUuzdBF"},"source":["# Test drive Code"]},{"cell_type":"code","source":["#subject_name = input(\"Enter the subject name: (for example: 's01'): \\n\")\n","#class_label = input(\"Enter the label ('valence', 'arousal', 'all'): \\n\")\n","subject_name = \"s01\"\n","class_label = \"valence\"\n","link = \"/content/drive/MyDrive/Deap/\" + subject_name + \".dat\"\n","with open(link, 'rb') as f:\n","  raw_data = pickle.load(f, encoding = 'latin1')\n","labels = raw_data['labels']\n","em_labels = emotion_label(labels, class_label) # get the emotion labels\n","channel_name = get_fisher_score(subject_name, em_labels)\n","optimal_channel_name = growing_phase(channel_name)\n","sort_channel_name = pruning_phase_get_fscore(optimal_channel_name, subject_name, em_labels)\n","final_channel_name = pruning_phase(sort_channel_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1vo7b4gdSO0-","executionInfo":{"status":"ok","timestamp":1639500850484,"user_tz":-330,"elapsed":7851,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}},"outputId":"a91cbade-c878-484a-aa13-cada817dcebc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy in Growing Phase:  0.725\n","No of selected channels in Growing Phase:  6\n","Channels selected in Growing Phase:  ['Fz', 'FC2', 'CP6', 'F7', 'Fp1', 'FC6']\n","Accuracy in Pruning Phase:  0.725\n","No of selected channels in Pruning Phase:  6\n","Channels selected in Pruning Phase:  ['Fz', 'FC2', 'CP6', 'F7', 'Fp1', 'FC6']\n"]}]},{"cell_type":"code","source":["print(channel_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1dV-UjVUFrf","executionInfo":{"status":"ok","timestamp":1639492833748,"user_tz":-330,"elapsed":398,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}},"outputId":"1da2510f-67ba-441a-9b28-d54c96456f6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Fz', 'FC2', 'CP6', 'Pz', 'P8', 'F4', 'CP1', 'AF4', 'CP2', 'P7', 'CP5', 'Fp2', 'AF3', 'F7', 'Fp1', 'Oz', 'F3', 'C4', 'PO3', 'FC1', 'O2', 'C3', 'O1', 'FC5', 'PO4', 'T8', 'F8', 'Cz', 'P3', 'FC6', 'T7', 'P4']\n"]}]},{"cell_type":"markdown","metadata":{"id":"pD-yBB7AzgaM"},"source":["# Main Drive Code"]},{"cell_type":"code","metadata":{"id":"GIp4yit8WZ6g"},"source":["subject_names = [\"s01\", \"s02\", \"s03\", \"s04\", \"s05\", \"s06\", \"s07\", \"s08\", \"s09\", \"s10\", \"s11\", \"s12\", \"s13\", \"s14\", \"s15\", \"s16\", \"s17\", \"s18\", \"s19\", \"s20\", \"s21\",\n","                \"s22\", \"s23\", \"s24\", \"s25\", \"s26\", \"s27\", \"s28\", \"s29\", \"s30\", \"s31\", \"s32\"]\n","class_labels = [\"arousal\", \"valence\", \"all\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6sfOKEtydoX"},"source":["for subject_name in subject_names:\n","  print(\"-\"*150)\n","  print(\"Subject Name: \", subject_name)\n","  print(\"-\"*150)\n","  for class_label in class_labels:\n","    print(\"Class Label: \", class_label)\n","    link = \"/content/drive/MyDrive/Deap/\" + subject_name + \".dat\"\n","    with open(link, 'rb') as f:\n","      raw_data = pickle.load(f, encoding = 'latin1')\n","    labels = raw_data['labels']\n","    em_labels = emotion_label(labels, class_label) # get the emotion labels\n","    channel_name = get_fisher_score(subject_name, em_labels)\n","    optimal_channel_name = growing_phase(channel_name)\n","    sort_channel_name = pruning_phase_get_fscore(optimal_channel_name, subject_name, em_labels)\n","    final_channel_name = pruning_phase(sort_channel_name)\n","  print(\"-\"*150)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I87VPcgk-SJp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# taking all the channels"],"metadata":{"id":"aUBDuCxtp7Vw"}},{"cell_type":"code","source":["cd /content/drive/MyDrive/Sequential methods for channel selection/Subject Dependent/Data Files/PSD features/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JneFTJNp9RW","executionInfo":{"status":"ok","timestamp":1644322642067,"user_tz":-330,"elapsed":800,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}},"outputId":"4d3d4db0-5a96-4e96-9081-74e1a5fc93b8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Sequential methods for channel selection/Subject Dependent/Data Files/PSD features\n"]}]},{"cell_type":"code","source":["subject_name = [\"s01\", \"s02\", \"s03\", \"s04\", \"s05\", \"s06\", \"s07\", \"s08\", \"s09\", \"s10\", \"s11\", \"s12\", \"s13\", \"s14\", \"s15\", \"s16\", \"s17\", \"s18\", \"s19\", \"s20\", \"s21\",\n","                \"s22\", \"s23\", \"s24\", \"s25\", \"s26\", \"s27\", \"s28\", \"s29\", \"s30\", \"s31\", \"s32\"]"],"metadata":{"id":"42tj0YR_sb0n","executionInfo":{"status":"ok","timestamp":1644322642067,"user_tz":-330,"elapsed":3,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["acc_val = []\n","for i in subject_name:\n","  data = pd.read_csv(i + '.csv')\n","  link = \"/content/drive/MyDrive/Deap/\" + i + \".dat\"\n","  with open(link, 'rb') as f:\n","    raw_data = pickle.load(f, encoding = 'latin1')\n","  labels = raw_data['labels']\n","  em_labels = emotion_label(labels, \"valence\")\n","  # Implementing cross validation\n","  k = 40\n","  kf = KFold(n_splits = k, shuffle = False)\n","  acc_score = []\n","  x = data\n","  y = np.array(em_labels)\n","  for train_index , test_index in kf.split(x):\n","      x_train , x_test = x.iloc[train_index,:],x.iloc[test_index,:]\n","      y_train , y_test = y[train_index] , y[test_index]\n","      model = svm.SVC(kernel = 'poly')\n","      model.fit(x_train, y_train)\n","      pred_values = model.predict(x_test)\n","      #pred_values = model.predict(x_test)\n","      acc = accuracy_score(pred_values , y_test)\n","      acc_score.append(acc)\n","  avg_acc_score = sum(acc_score)/k\n","  avg_acc_score = avg_acc_score*100\n","  acc_val.append(avg_acc_score)"],"metadata":{"id":"Zapaof32r4EG","executionInfo":{"status":"ok","timestamp":1644322724362,"user_tz":-330,"elapsed":75744,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(acc_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbXEJ-fKuGCO","executionInfo":{"status":"ok","timestamp":1644322745837,"user_tz":-330,"elapsed":475,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}},"outputId":"e16a8d19-afda-40fe-9b20-02308f8357ef"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[52.5, 57.49999999999999, 65.0, 57.49999999999999, 72.5, 70.0, 70.0, 57.49999999999999, 62.5, 60.0, 32.5, 62.5, 80.0, 70.0, 52.5, 57.49999999999999, 45.0, 70.0, 70.0, 70.0, 50.0, 65.0, 60.0, 57.49999999999999, 70.0, 25.0, 72.5, 67.5, 55.00000000000001, 62.5, 52.5, 57.49999999999999]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Arousal\n","\"\"\"\n","acc_ar = []\n","for i in subject_name:\n","  data = pd.read_csv(i + '.csv')\n","  link = \"/content/drive/MyDrive/Deap/\" + i + \".dat\"\n","  with open(link, 'rb') as f:\n","    raw_data = pickle.load(f, encoding = 'latin1')\n","  labels = raw_data['labels']\n","  em_labels = emotion_label(labels, \"arousal\")\n","  # Implementing cross validation\n","  k = 40\n","  kf = KFold(n_splits = k, shuffle = False)\n","  acc_score = []\n","  x = data\n","  y = np.array(em_labels)\n","  for train_index , test_index in kf.split(x):\n","      x_train , x_test = x.iloc[train_index,:],x.iloc[test_index,:]\n","      y_train , y_test = y[train_index] , y[test_index]\n","      model = svm.SVC(kernel = 'poly')\n","      model.fit(x_train, y_train)\n","      pred_values = model.predict(x_test)\n","      #pred_values = model.predict(x_test)\n","      acc = accuracy_score(pred_values , y_test)\n","      acc_score.append(acc)\n","  avg_acc_score = sum(acc_score)/k\n","  avg_acc_score = avg_acc_score*100\n","  acc_ar.append(avg_acc_score)"],"metadata":{"id":"xmvrLJO3urVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(acc_ar)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lBwKGaPRvCj3","executionInfo":{"status":"ok","timestamp":1644095644183,"user_tz":-330,"elapsed":3,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}},"outputId":"f5eb2162-e8d4-443b-cf6a-5c0b9c8ab857"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[57.49999999999999, 42.5, 75.0, 60.0, 17.5, 47.5, 60.0, 52.5, 55.00000000000001, 60.0, 67.5, 75.0, 70.0, 67.5, 60.0, 62.5, 77.5, 67.5, 67.5, 77.5, 72.5, 60.0, 75.0, 82.5, 62.5, 70.0, 60.0, 57.49999999999999, 60.0, 65.0, 62.5, 52.5]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Four Class\n","\"\"\"\n","acc_four = []\n","for i in subject_name:\n","  data = pd.read_csv(i + '.csv')\n","  link = \"/content/drive/MyDrive/Deap/\" + i + \".dat\"\n","  with open(link, 'rb') as f:\n","    raw_data = pickle.load(f, encoding = 'latin1')\n","  labels = raw_data['labels']\n","  em_labels = emotion_label(labels, \"all\")\n","  # Implementing cross validation\n","  k = 40\n","  kf = KFold(n_splits = k, shuffle = False)\n","  acc_score = []\n","  x = data\n","  y = np.array(em_labels)\n","  for train_index , test_index in kf.split(x):\n","      x_train , x_test = x.iloc[train_index,:],x.iloc[test_index,:]\n","      y_train , y_test = y[train_index] , y[test_index]\n","      model = svm.SVC(kernel = 'poly')\n","      model.fit(x_train, y_train)\n","      pred_values = model.predict(x_test)\n","      #pred_values = model.predict(x_test)\n","      acc = accuracy_score(pred_values , y_test)\n","      acc_score.append(acc)\n","  avg_acc_score = sum(acc_score)/k\n","  avg_acc_score = avg_acc_score*100\n","  acc_four.append(avg_acc_score)"],"metadata":{"id":"XOlhRonpvEOG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(acc_four)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2EsYL37vT6k","executionInfo":{"status":"ok","timestamp":1644095811150,"user_tz":-330,"elapsed":535,"user":{"displayName":"SHYAM MARJIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64","userId":"10874093040693940713"}},"outputId":"7f5879e8-27a7-4592-bf8e-1cdea6960fe9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[20.0, 37.5, 42.5, 42.5, 22.5, 32.5, 32.5, 30.0, 32.5, 35.0, 40.0, 47.5, 55.00000000000001, 50.0, 27.500000000000004, 27.500000000000004, 40.0, 32.5, 27.500000000000004, 55.00000000000001, 30.0, 40.0, 50.0, 47.5, 35.0, 47.5, 57.49999999999999, 37.5, 45.0, 15.0, 42.5, 27.500000000000004]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"_yZmbXB4vVS3"},"execution_count":null,"outputs":[]}]}